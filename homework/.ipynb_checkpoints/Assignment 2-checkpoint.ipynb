{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2\n",
    "* Due: Tuesday 2/18/2020 by  5 PM \n",
    "* Topics: pandas and numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "* Download your notebook as a PDF\n",
    "* Turn in both the notebook and PDF\n",
    "* Show the output of your code working on the sample data, like below.  \n",
    "* If techniques are specified, use them.  Otherwise, feel free to solve the problem how you want.  \n",
    "* Try to keep your code clean, concise and avoid loops if necessary.  \n",
    "* You have to show your work (code).\n",
    "* You will be graded:\n",
    "    * The functionality of your code (Does it do what it was meant to)\n",
    "    * Showing the output on the sample data provided\n",
    "    * How concise it is (did you use a for loop when you could have used a comprehension for instance).  Simply put, try and write clean, concise and readable code (don't use 10 lines for what could have been done in 4).\n",
    "    * Even if the answer isn't perfect, make an honest attempt as partial credit will be given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "* sklearn has the iris dataset built in\n",
    "* this is what we will be working with\n",
    "* put the iris data into a dataframe where we have 5 columns (the 4 features and the target)\n",
    "* but the target shouldn't be numerical, it should be the actual label (so put setosa not 0 in the target column) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "* using the data array from the iris variable (should be a numpy array of size 150x4), for each row and column, find the sum, min and max\n",
    "* print out the results, but for the rows, show only the first 5 elements of the array and display the length (otherwise it will be large arrays since each row has a value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "* write a function to return the multiplication of two matrices\n",
    "* use some sort of error handling to make sure the dimensions are compatible\n",
    "* use teh function to multiply the iris data (don't use the label column) by it's transpose\n",
    "* what are the dimensions of the result\n",
    "* put the sum of each row of the resulting matrix into a vector, printing out the length and first 5 elements.\n",
    "* put the sum of each column of the resulting matrix in a vector and print it out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "* create a subset of the iris dataframe that doesn't have the label column\n",
    "* for each row, find the index of the min and max feature value\n",
    "    * if we have a row with values [10,2,3,4] we want to return 1 for min and 0 for max, as these are the indicies that align to the min and max values\n",
    "* the result should be two arrays of length 150 (one for each row) with the indices of the min and max value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "* Use the above two arrays to make a dataframe with 2 columns, the first being the feature of minimum value and the second the feature name of the maximum value\n",
    "* note, don't have the cell values be the index value of the min/max value, have it be the feature name\n",
    "    * a row should be [min_val = sepal width (cm), max_val = petal length (cm)]\n",
    "* show the distributions for max and min features (how many times is each feature the max and min value for a row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "* Describe a situation the functionality from question 4 and 5 could be of use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "* sort the feature values for each row and replace the indices with the feature names\n",
    "    * so each row will have 4 columns, the first column being the feature name that is the highest value, the second column being the feature name that is the second highest value, etc.\n",
    "* note, watch out how argsort in numpy works.  you will need to reverse the order somehow.  the sorted(reverse = True) functionality might be of help.\n",
    "* make sure to replace the index values with the feature name, as we did above\n",
    "* put the resulting 2-d array into a pandas dataframe and print the first 5 rows.\n",
    "* hint, look at the apply_along_axis() method for numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8\n",
    "* apply z-score normalization to each column in the iris data (note you do not need the target/label column)\n",
    "* column wise meaning, treat each column as an array, and find the standard deviations and means of that column\n",
    "* note, you can use zscore from scipy.stats\n",
    "* results should be a pandas dataframe, printing out 5 rows and running the describe() method on the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9\n",
    "* make a function that takes in a 2d numpy array X, a 1d numpy array Y and the size the training data, test data and valiation datasets.  \n",
    "* return 6 items\n",
    "    * train_x, train_y, test_x, test_y, val_x, val_y\n",
    "* do not use any modules.  this can be solved using bracket notation to subset.  Note // will take care of decimals in doing division. you could also use int() to convert the float to a whole number\n",
    "* make the params for the training, test and val size be decimals, that repsent percentages of the data.  For instance .8, .1, .1 means an 80% training, 10% test and 10% validation split\n",
    "* use an assert to make sure the numbers add to 1\n",
    "* print out the dimensions of all 6 elements, using iris as a test case with an 80-10-10 split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 10\n",
    "* using pandas, find the sum of each feature by species type (label)\n",
    "* do the same, but find the min, max and median as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 11\n",
    "* mean center each column of the iris dataframe (excluding the label column of course)\n",
    "* this means, for each column, the mean should be zero.  to accomplish this we can subtract the column mean from each element of the column\n",
    "* note, broadcasting, which if we have say a 150 row and 4 column dataframe, can  take a row vector of size 4 and apply it to each element\n",
    "*  thus, we can answer this questions doing something like df - df_col_means\n",
    "* run the describe() method at the end to show the data has been mean center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quesiton 12\n",
    "* Explain what the axis mean in regards to a pandas dataframe and numpy array\n",
    "* How would you groupby two columns in pandas?\n",
    "* What functions are used to read in csvs and excel files in pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 13\n",
    "* using Pandas, subset the dataset for only species setosa and petal length > 1.3\n",
    "* sum the feature columns and display the results for each (excluding the label column)\n",
    "* do the same, but change the and to an or, and repeat the same calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 14\n",
    "* write a lambda that subtracts 2 from all elements of a pandas dataframe\n",
    "* display the top 5 rows\n",
    "* use the same lambda,  but applying it to the sepal length  column only\n",
    "* so the output should be the top 5 rows of a dataframe where all cells have had 2 subtracted and then another dataframe where only sepal length has 2 subtracted from it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 15\n",
    "* normalize each column of pandas dataframe to 0-1 scale.\n",
    "* hint\n",
    "    * 0-1 is done by using (X - xmin)/(xmax - xmin)\n",
    "    * hint, the approach should be similar to when we mean centered the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 16\n",
    "* assume the below 2 matrices, the first is observations and the second is cluster centers\n",
    "* using cdist from scipy, create a matrix where the rows represent our 3 observations and the columns represent our 2 clusters and the cells values are the euclidean distances between a given observation and cluster\n",
    "* when would this be of use?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = np.array([\n",
    "    [1,2,3],\n",
    "    [4,3,1],\n",
    "    [2,3,4]\n",
    "])\n",
    "\n",
    "cluster_centers = np.array([\n",
    "    [2,3,1],\n",
    "    [2,1,3]\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
